{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b9251ac-823f-49d1-8850-fd181ee3b999",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.multiprocessing as mp\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from sklearn.decomposition import PCA\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import random\n",
    "import math\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9988e454-aa42-4a32-8e3b-34c810dcc1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm=pd.read_csv(\"/storage/homefs/ts18c034/MasterKinase/data/HumanKinomeSeqFamilyClassification_centered_20substrates.csv\") #was 80 before\n",
    "\n",
    "model_src = \"/storage/homefs/ts18c034/MasterKinase/ESM-2/esm2_t12_35M_UR50D\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_src, from_tf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cee951ef-d8c7-4d27-9843-0b8d1becc489",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KinaseDataset(Dataset):\n",
    "    def __init__(self, tokenized, labels, device):\n",
    "        self.tokenized = tokenized\n",
    "        self.labels = labels\n",
    "        self.device = device\n",
    "\n",
    "        # Convert labels to numerical format\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.encoded_labels = torch.tensor(self.label_encoder.fit_transform(self.labels), dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encoded_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tokenized_sample = {key: value[idx].to(self.device) for key, value in self.tokenized.items()}  \n",
    "        label = self.encoded_labels[idx].to(self.device)\n",
    "\n",
    "        return tokenized_sample, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3b045f04-0abc-4866-acab-66b2842e0a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0e166a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = tokenizer(dfm[\"Centered_Kinase_Sequence\"].tolist(), return_tensors=\"pt\",truncation=False) \n",
    "\n",
    "labels=dfm[\"HGNC Name \"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c250b300-36fa-4bf5-a774-a559791ecf1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at /storage/homefs/ts18c034/MasterKinase/ESM-2/esm2_t12_35M_UR50D and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "torch_model = AutoModel.from_pretrained(model_src, from_tf=False) #AutoModel already loads only the embedding layers and not the classifier head so we dont have to truncate the model.\n",
    "\n",
    "torch_model.config.output_hidden_states = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dab1c73e-1f9d-45c1-b9ba-94d2c9f37e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_model = torch_model.to(device) #\"move\" model to GPU if applicable\n",
    "\n",
    "\n",
    "torch_model.eval()\n",
    "\n",
    "\n",
    "all_embeddings = []\n",
    "all_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "846a2574",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = KinaseDataset(tokenized, labels, device)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5c04ea96-9dcb-4614-b897-f1305cdabf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for batch in dataloader:\n",
    "        tokenized_batch, labels_batch = batch  # Extract batch of tokenized sequences and labels\n",
    "        \n",
    "        # Pass batch through the model\n",
    "        torch_output = torch_model(**tokenized_batch)\n",
    "\n",
    "        #extract final layer\n",
    "        final_layer_embeddings = torch_output.hidden_states[11]\n",
    "\n",
    "        all_labels.append(labels_batch)\n",
    "        all_embeddings.append(final_layer_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "40309ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([301, 1023, 480])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(all_embeddings, dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "85e373ec-bff1-49df-8c5c-cdc0728d68e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings=torch.cat(all_embeddings,dim=0)\n",
    "all_labels=torch.cat(all_labels,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ff621ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1023, 480])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_embeddings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79286dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(all_embeddings,\"/storage/homefs/ts18c034/MasterKinase/ESM-2/kinasetokenized/301kinases_35M_centered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b73112",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(all_labels,\"/storage/homefs/ts18c034/MasterKinase/ESM-2/kinasetokenized/301kinases_35M_centered\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchtest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
